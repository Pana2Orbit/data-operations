{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec637f23",
   "metadata": {},
   "source": [
    "# Import Required Libraries\n",
    "Import necessary libraries such as google.cloud.aiplatform, datetime, and croniter for Vertex AI pipeline management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527a2faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "from google.cloud import aiplatform\n",
    "from kfp.v2 import compiler\n",
    "from src.pipelines.earth_data_to_bq import earth_data_pipeline  # Assuming the pipeline is importable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9466d9",
   "metadata": {},
   "source": [
    "# Define Pipeline Parameters\n",
    "Define and validate input parameters including dataset_name, dataset_version, is_scheduled, start_date, end_date, and cron_schedule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e258d3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "dataset_name = \"MODIS\"  # Example\n",
    "dataset_version = \"061\"\n",
    "is_scheduled = False  # True for scheduled, False for immediate run\n",
    "start_date = \"2023-01-01\" if not is_scheduled else None\n",
    "end_date = \"2023-01-02\" if not is_scheduled else None\n",
    "cron_schedule = \"0 0 * * *\" if is_scheduled else None  # Daily at midnight\n",
    "\n",
    "# Other required parameters\n",
    "polygon = [[-122.0, 37.0], [-122.0, 38.0], [-121.0, 38.0], [-121.0, 37.0]]\n",
    "polygon_str = json.dumps(polygon)\n",
    "bq_dataset = \"your_bq_dataset\"\n",
    "table_id = \"your_table\"\n",
    "\n",
    "# Validate\n",
    "if is_scheduled and not cron_schedule:\n",
    "    raise ValueError(\"cron_schedule must be provided if is_scheduled is True\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d94e51",
   "metadata": {},
   "source": [
    "# Create Pipeline Function\n",
    "The pipeline function is already defined in src.pipelines.earth_data_to_bq. We use it directly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53163b2b",
   "metadata": {},
   "source": [
    "# Compile Pipeline\n",
    "Compile the pipeline into a JSON format suitable for Vertex AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecefac57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the pipeline\n",
    "pipeline_json_path = \"earth_data_pipeline.json\"\n",
    "compiler.Compiler().compile(\n",
    "    pipeline_func=earth_data_pipeline,\n",
    "    package_path=pipeline_json_path\n",
    ")\n",
    "print(f\"Pipeline compiled to {pipeline_json_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932caeeb",
   "metadata": {},
   "source": [
    "# Schedule Pipeline\n",
    "If is_scheduled is True, use cron_schedule to create a scheduled run in Vertex AI, ignoring start_date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d43c6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schedule the pipeline if requested\n",
    "if is_scheduled:\n",
    "    aiplatform.init(project=\"your-gcp-project\", location=\"us-central1\")\n",
    "    pipeline_job = aiplatform.PipelineJob(\n",
    "        display_name=\"Scheduled Earth Data Pipeline\",\n",
    "        template_path=pipeline_json_path,\n",
    "        parameter_values={\n",
    "            \"dataset_name\": dataset_name,\n",
    "            \"dataset_version\": dataset_version,\n",
    "            \"polygon_str\": polygon_str,\n",
    "            \"bq_dataset\": bq_dataset,\n",
    "            \"table_id\": table_id,\n",
    "            # start_date and end_date will be None, so pipeline uses current dates\n",
    "        }\n",
    "    )\n",
    "    schedule = aiplatform.Schedule.create(\n",
    "        pipeline_job=pipeline_job,\n",
    "        cron=cron_schedule,\n",
    "        display_name=\"Earth Data Schedule\"\n",
    "    )\n",
    "    print(f\"Pipeline scheduled with ID: {schedule.resource_name}\")\n",
    "else:\n",
    "    print(\"Pipeline not scheduled.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e006a2db",
   "metadata": {},
   "source": [
    "# Run Pipeline Immediately\n",
    "If is_scheduled is False, run the pipeline immediately in Vertex AI using start_date and end_date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94fbcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the pipeline immediately if not scheduled\n",
    "if not is_scheduled:\n",
    "    aiplatform.init(project=\"your-gcp-project\", location=\"us-central1\")\n",
    "    job = aiplatform.PipelineJob(\n",
    "        display_name=\"Earth Data Pipeline Run\",\n",
    "        template_path=pipeline_json_path,\n",
    "        parameter_values={\n",
    "            \"dataset_name\": dataset_name,\n",
    "            \"dataset_version\": dataset_version,\n",
    "            \"start_date\": start_date,\n",
    "            \"end_date\": end_date,\n",
    "            \"polygon_str\": polygon_str,\n",
    "            \"bq_dataset\": bq_dataset,\n",
    "            \"table_id\": table_id\n",
    "        }\n",
    "    )\n",
    "    job.run()\n",
    "    print(f\"Pipeline run started with ID: {job.resource_name}\")\n",
    "else:\n",
    "    print(\"Pipeline is scheduled, not running immediately.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcb831c",
   "metadata": {},
   "source": [
    "# Delete Pipeline\n",
    "Delete an existing pipeline from Vertex AI using its resource name or ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed9ffd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete a pipeline (run this cell separately with the resource name)\n",
    "# Replace 'your-pipeline-resource-name' with the actual resource name from previous runs\n",
    "pipeline_resource_name = \"projects/your-gcp-project/locations/us-central1/pipelineJobs/your-job-id\"\n",
    "aiplatform.PipelineJob.delete(resource_name=pipeline_resource_name)\n",
    "print(f\"Deleted pipeline: {pipeline_resource_name}\")\n",
    "\n",
    "# For schedules, if deleting a schedule:\n",
    "# schedule_resource_name = \"projects/.../schedules/...\"\n",
    "# aiplatform.Schedule.delete(resource_name=schedule_resource_name)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
